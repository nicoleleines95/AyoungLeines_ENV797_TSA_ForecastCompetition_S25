---
title: "Competition with Temperature "
author: "Ayoung Kim"
date: "2025-04-08"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

You should download the dataset from the Kaggle platform. There are three datasets: one with hourly demand, one with hourly temperature, and one with hourly relative humidity from January 2005 to December 2010. Note that the format of the data differs. Your goal is to forecast daily load for January and February of 2011 based on this historical data. You may or may not use the temperature and relative humidity in your models. The temperature and humidity measurements come from stations close to the household meter data you have.

Wrangle/Process the Dataset
You will need to transform the hourly data into daily data. See the Rmd file from Module 9 (TBD) for instructions on how to aggregate your dataset using pipes. Take the average of the 24-hour data points to obtain the daily averages.

Create a Time Series Object
After processing your dataset, use the msts() function to create a time series object. You need to use msts() instead of ts() because your daily data has more than one seasonal component.



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(lubridate)
library(readxl)
library(tidyverse)
library(forecast)
library(tseries)
library(kableExtra)
library(smooth)
library(cowplot)

```

```{r}
# Load the dataset
daily_data <- read_excel("./Data/load.xlsx")

# Confirm that date is parsed correctly
head(daily_data$date)  # you MUST see valid dates like 2005-01-01

# Aggregate hourly to daily
daily_data <- daily_data %>%
  mutate(Value = rowMeans(select(., starts_with("h")), na.rm = TRUE))

daily_data$date <- as.Date(daily_data$date)
daily_data$date <- ymd(daily_data$date)

head(daily_data)

#Upload temperature 
daily_temp<-read_excel("./Data/temperature.xlsx")

daily_temp<-daily_temp %>%
  mutate(Value_hour=rowMeans(select(., starts_with("t_ws")), na.rm=TRUE))

daily_temp$date <- as.Date(daily_temp$date)
daily_temp$date <- ymd(daily_temp$date)

head(daily_temp)

#Aggregated by date
daily_temp_aggregated <- daily_temp %>%
  group_by(date) %>%
  summarise(Temperature = mean(Value_hour, na.rm = TRUE))

#Merge the datasets 
combined_data <- left_join(daily_data, daily_temp_aggregated, by = "date")

print(combined_data)


#ts daily 
ts_daily <- ts(
  combined_data$Value,  # Take only the first 2191 values
  start = c(2005, 1),
  frequency = 365
)

temp_daily <- combined_data$Temperature

print(ts_daily)
autoplot(ts_daily)

adf.test(ts_daily)

# Merge daily load and daily temperature
combined_data <- left_join(daily_data, daily_temp %>% select(date, Temperature), by = "date")

# Check merged data
head(combined_data)

```

```{r, warning=FALSE}
#create a subset for training purpose
n_for <- 59

# Training set (up to Dec 31, 2010)
ts_train <- window(ts_daily, end = c(2010, 365))
temp_train <- temp_daily[1:(length(temp_daily) - n_for)]

# Test set (Janâ€“Feb 2011)
ts_test <- window(ts_daily, start = c(2011, 1))
temp_test <- temp_daily[(length(temp_daily) - n_for + 1):length(temp_daily)]


```


### Model 1: STL + ETS
```{r ETS}
# Train STL+ETS
ETS_fit <- stlf(ts_train, h = 59)
print(ETS_fit)

print(ETS_fit$mean)

autoplot(ETS_fit)

autoplot(ts_daily) +
  autolayer(ETS_fit, series="STL + ETS") +
  theme_minimal()
```

### Model 2: ARIMA + FOURIER terms

```{r ARIMA, echo=TRUE, message=FALSE, warning=FALSE}
# Train simple ARIMA on training data
ARIMA_simple <- auto.arima(ts_train)
print(ARIMA_simple)

# Forecast simple ARIMA
ARIMA_simple_forecast <- forecast(object = ARIMA_simple, h = 59)

# Plot simple ARIMA forecast
autoplot(ts_daily) +
  autolayer(ARIMA_simple_forecast, series = "Simple ARIMA", PI = FALSE) +
  ylab("Load") +
  theme_minimal() +
  ggtitle("Simple ARIMA - Daily Load")

# Train ARIMA with Fourier terms
# (you can adjust K to better fit your seasonal patterns)
K_val <- 6  # Fourier term choice

# Fit ARIMA + Fourier + Temperature
ARIMA_fourier_temp <- auto.arima(ts_train,
                                 seasonal = FALSE,
                                 lambda = 0,
                                 xreg = cbind(fourier(ts_train, K = K_val), temp_train)
                                 )

# Forecast
ARIMA_fourier_forecast <- forecast(ARIMA_fourier_temp,
                                   xreg = cbind(fourier(ts_train, K = K_val, h = 59), temp_test),
                                   h = 59
                                   )

print(ARIMA_fourier_forecast)

```
### Model 4: Neural Network Time Series Forecasts

```{r NNETAR, echo=TRUE, message=FALSE, warning=FALSE}
# Train Neural Network (NNETAR) model with Fourier terms
# Fit Neural Network model
NN_fit <- nnetar(ts_train,
                 p = 1,
                 P = 1,
                 xreg = cbind(fourier(ts_train, K = 2), temp_train)
                 )

# Forecast
NN_forecast <- forecast(NN_fit,
                        h = 59,
                        xreg = cbind(fourier(ts_train, K = 2, h = 59), temp_test)
                        )

print(NN_forecast)


# Plot forecasting results
autoplot(NN_forecast) +
  ylab("Load") +
  theme_minimal() +
  ggtitle("Neural Network Forecast - Daily Load")

# Plot model + observed test data
autoplot(ts_daily) +
  autolayer(NN_forecast, series = "Neural Network", PI = FALSE) +
  autolayer(ts_test, series = "Observed", color = "black") +
  ylab("Load") +
  theme_minimal() +
  ggtitle("Neural Network vs Observed - Daily Load")

# Plot combined results
autoplot(ts_daily) +
  autolayer(NN_forecast, series = "Neural Network") +
  autolayer(ts_test, series = "Observed", color = "black") +
  ylab("Load") +
  theme_minimal() +
  ggtitle("Neural Network vs Observed - Daily Load (Zoomed In)")

```

## Checking accuracy of the forecast models

```{r}
# Model 1: STL + ETS
ETS_scores <- accuracy(ETS_fit$mean, ts_test)

# Model 2: ARIMA + Fourier
ARIMA_scores <- accuracy(ARIMA_fourier_forecast$mean, ts_test)

# Model 3: TBATS (if you built TBATS separately, otherwise comment this out)
TBATS_scores <- accuracy(TBATS_forecast$mean, ts_test)

# Model 4: Neural Network
NN_scores <- accuracy(NN_forecast$mean, ts_test)

# Display the scores
ETS_scores
ARIMA_scores
TBATS_scores 
NN_scores

```

```{r}
# Make it a data frame
scores_load <- as.data.frame(
  rbind(ETS_scores, ARIMA_scores, TBATS_scores, NN_scores)
)
row.names(scores_load) <- c("STL + ETS", "ARIMA + Fourier", "TBATS", "Neural Network")

# Choose model with lowest RMSE
best_model_load <- which.min(scores_load[,"RMSE"])
cat("The best model by RMSE is:", row.names(scores_load[best_model_load,]), "\n")

# Create nice kable table
library(kableExtra)

kbl(scores_load,
    caption = "Forecast Accuracy for Daily Load",
    digits = array(5, ncol(scores_load))) %>%
  kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position") %>%
  kable_styling(latex_options = "striped", stripe_index = best_model_load)

```
### Plotting everything together 
```{r}
autoplot(ts_test) +
  autolayer(ETS_fit, PI=FALSE, series="STL+ETS") +
  autolayer(ARIMA_forecast, PI=FALSE, series="ARIMA + Fourier") +
  autolayer(TBATS_forecast,PI=FALSE, series="TBATS") +
  autolayer(NN_forecast,PI=FALSE, series="Neural Network") +
  ylab("Daily Load") +
  guides(colour=guide_legend(title="Forecast"))
```